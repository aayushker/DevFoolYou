# MongoDB Data Pipeline - Usage Guide

## Overview

This folder contains scripts to manage your DevFoolYou project database on MongoDB Atlas.

## Scripts

### 1. `csvToAtlas.py` - CSV to MongoDB Importer

**Purpose**: Import project data from CSV to MongoDB with duplicate checking.

**Features**:

- ‚úÖ Reads from the new CSV format (with exact column names matching MongoDB schema)
- ‚úÖ Checks for duplicates using `urlOfProject` before inserting
- ‚úÖ Batch insertion for better performance
- ‚úÖ Detailed progress reporting

**Column Mapping** (New CSV Format):

```
CSV Columns (Required):
- urlOfProject
- nameOfProject
- descriptionOfProject
- problemSolved
- challengesFaced
- technologiesUsed (comma-separated string)
```

**Usage**:

```bash
python csvToAtlas.py
```

The script will:

1. Read `projects_data.csv`
2. Check existing projects in MongoDB
3. Skip duplicates (based on URL)
4. Insert only new projects
5. Show detailed progress

**Output Example**:

```
Total documents to process: 150
Duplicates found (skipped): 25
New documents to insert: 125
‚úì Inserted batch 1: 100 documents
‚úì Inserted batch 2: 25 documents
```

---

### 2. `generate_and_update_embeddings.py` - Embedding Generator

**Purpose**: Generate embeddings for projects using the `all-MiniLM-L6-v2` model.

**Features**:

- ‚úÖ Uses `sentence-transformers/all-MiniLM-L6-v2` (384-dimensional embeddings)
- ‚úÖ Fetches projects from MongoDB one by one
- ‚úÖ Skips projects that already have embeddings
- ‚úÖ Updates MongoDB with generated embeddings
- ‚úÖ Creates rich text from multiple fields for better semantic search

**Text Combination Strategy**:
For each project, the script combines:

- Project name
- Description
- Problem solved
- Challenges faced
- Technologies used

**Usage**:

```bash
python generate_and_update_embeddings.py
```

The script will:

1. Load the embedding model (downloads on first run ~90MB)
2. Connect to MongoDB
3. Find projects without embeddings
4. Generate embeddings for each project
5. Update MongoDB documents
6. Show progress and summary

**Output Example**:

```
Found 150 projects in the database.

[1/150] üîÑ Processing: 'Dress colour changer'
[1/150] ‚úÖ Updated with 384-dim embedding
[2/150] ‚è≠Ô∏è  Skipping 'Circuit Solver' (already has embeddings)
...

üìä Summary:
   Total projects: 150
   ‚úÖ Successfully updated: 125
   ‚è≠Ô∏è  Skipped (already had embeddings): 25
   ‚ùå Failed: 0
```

---

## Recommended Workflow

### Initial Setup:

1. **Whitelist your IP** in MongoDB Atlas:

   - Go to: https://cloud.mongodb.com
   - Network Access ‚Üí Add IP Address ‚Üí Allow from Anywhere (0.0.0.0/0)

2. **Install dependencies**:
   ```bash
   pip install pymongo sentence-transformers pandas
   ```

### Data Import and Embedding Generation:

```bash
# Step 1: Import CSV data to MongoDB
python csvToAtlas.py

# Step 2: Generate embeddings for all projects
python generate_and_update_embeddings.py
```

### Updating with New Data:

```bash
# Add new projects to projects_data.csv, then:
python csvToAtlas.py          # Only new projects will be inserted
python generate_and_update_embeddings.py  # Only new projects will get embeddings
```

---

## MongoDB Schema

```javascript
{
  "urlOfProject": String (required, unique identifier),
  "nameOfProject": String (required),
  "descriptionOfProject": String (required),
  "problemSolved": String (required),
  "challengesFaced": String (required),
  "technologiesUsed": Array of Strings (required),
  "embeddingsOfData": Array of Numbers (384 dimensions, generated by script)
}
```

---

## Embedding Model Details

**Model**: `sentence-transformers/all-MiniLM-L6-v2`

**Why this model?**

- ‚úÖ Fast inference (good for real-time search)
- ‚úÖ Small size (~90MB)
- ‚úÖ 384 dimensions (good balance)
- ‚úÖ Excellent for short texts (project descriptions)
- ‚úÖ Free and open-source
- ‚úÖ Works great with MongoDB vector search

**Performance**:

- ~500-1000 texts/second on CPU
- ~100ms for generating embeddings for 150 projects

---

## Troubleshooting

### Connection Issues:

```
Error: No replica set members match selector "Primary()"
```

**Solution**: Whitelist your IP address in MongoDB Atlas Network Access

### Duplicate Key Errors:

The scripts handle duplicates automatically using `urlOfProject` as the unique identifier.

### Embedding Generation Slow:

- First run downloads the model (~90MB)
- Subsequent runs are much faster
- CPU-based inference is normal for this model

---

## Files in This Directory

- `csvToAtlas.py` - CSV import script
- `generate_and_update_embeddings.py` - Embedding generation script
- `projects_data.csv` - Your project data (CSV format)
- `atlasTable.py` - MongoDB schema and validation setup
- `README_USAGE.md` - This file

---

## Next Steps

After importing and generating embeddings, you can:

1. Build a similarity search API
2. Create a recommendation system
3. Enable semantic search on your frontend
4. Use MongoDB Atlas Vector Search for fast queries

Enjoy! üöÄ
